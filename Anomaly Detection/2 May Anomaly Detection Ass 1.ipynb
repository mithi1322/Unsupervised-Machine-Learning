{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da09779c-f4e1-4fd8-921b-b6ccd3e778dd",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly scoreusing KNN with K=10?\n",
    "\n",
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b276311c-3901-40fa-b045-ec1c1087149d",
   "metadata": {},
   "source": [
    "# Answer 1:\n",
    "Anomaly detection, also known as outlier detection, is the process of identifying rare and unusual patterns or data points in a dataset that deviate significantly from the majority of the data. Its purpose is to detect and flag observations that are abnormal or unexpected, as these anomalies may indicate potential fraud, errors, faults, or unusual behavior in various applications.\n",
    "# Answer 2:\n",
    "The key challenges in anomaly detection include:\n",
    "\n",
    "1. Lack of Anomalous Data: Anomalies are often rare, making it challenging to collect sufficient anomalous data for training and evaluation.\n",
    "\n",
    "2. Unbalanced Data: Anomaly detection datasets are typically highly imbalanced, with a small number of anomalies compared to the majority of normal data points. This can lead to biased models.\n",
    "\n",
    "3. High-Dimensional Data: Anomaly detection becomes more complex as the dimensionality of the data increases (curse of dimensionality).\n",
    "\n",
    "4. Concept Drift: The underlying data distribution may change over time, making it difficult to maintain the performance of an anomaly detection model in dynamic environments.\n",
    "\n",
    "5. Definition of Anomaly: Defining what constitutes an anomaly may be subjective and context-dependent.\n",
    "# Answer 3:\n",
    "Unsupervised anomaly detection does not require labeled data with explicit information about anomalies during training. It identifies anomalies based on the assumption that anomalies deviate significantly from the normal data distribution. On the other hand, supervised anomaly detection relies on labeled data, where anomalies are explicitly identified during training. The model learns from both normal and anomalous instances and is trained to classify data points as either normal or anomaly.\n",
    "# Answer 4:\n",
    "The main categories of anomaly detection algorithms are:\n",
    "\n",
    "1. Statistical Methods: These methods use statistical techniques to model the normal data distribution and identify data points that fall outside the expected distribution.\n",
    "\n",
    "2. Distance-Based Methods: These algorithms measure the distance between data points and their neighbors to detect outliers that have unusual distances from the majority of the data.\n",
    "\n",
    "3. Density-Based Methods: These methods identify anomalies based on the assumption that anomalies are located in sparse regions with low data density.\n",
    "\n",
    "4. Clustering-Based Methods: These algorithms group data points into clusters and identify data points that do not belong to any cluster as anomalies.\n",
    "\n",
    "5. Machine Learning-Based Methods: These techniques use machine learning models, such as Isolation Forest and Local Outlier Factor (LOF), to identify anomalies based on learned patterns from the data.\n",
    "# Answer 5:\n",
    "Distance-based anomaly detection methods assume that anomalies are located far away from the majority of the data points. These methods often compute the distance or dissimilarity between data points and their neighbors. They assume that anomalies have significantly larger distances compared to normal data points.\n",
    "# Answer 6:\n",
    "The Local Outlier Factor (LOF) algorithm computes anomaly scores for data points based on the density of their local neighborhood. The algorithm compares the density of a data point's neighborhood to the densities of its k-nearest neighbors. If a data point has a much lower density compared to its neighbors, it is considered an anomaly.\n",
    "# Answer 7:\n",
    "The key parameters of the Isolation Forest algorithm are:\n",
    "\n",
    "1. n_estimators: The number of isolation trees in the forest. Increasing the number of trees generally improves the performance but also increases computation time.\n",
    "\n",
    "2. max_samples: The number of samples used to build each isolation tree. Smaller values increase the randomness of the trees but may lead to less accurate results.\n",
    "\n",
    "3. contamination: The proportion of anomalies expected in the data. This parameter helps control the threshold for anomaly detection.\n",
    "# Answer 8:\n",
    "Using the k-nearest neighbors (KNN) algorithm with K=10, if a data point has only 2 neighbors of the same class within a radius of 0.5, its anomaly score would be relatively high. Having only two neighbors of the same class within a small radius indicates that the data point is far from its majority neighbors, which increases its likelihood of being an anomaly.\n",
    "# Answer 9:\n",
    "In the Isolation Forest algorithm, the anomaly score for a data point is calculated as the average path length of the data point across all isolation trees. The average path length is normalized by a factor that depends on the number of data points (n) and the number of trees (t) in the forest. The anomaly score ranges between 0 and 1, where higher values indicate higher likelihood of being an anomaly. Without the exact values of n and t in the dataset, we cannot calculate the precise anomaly score for a data point with an average path length of 5.0. However, generally, shorter average path lengths are associated with higher anomaly scores, indicating that the data point is more likely to be an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22dc703-683c-4282-94c1-02c9c429128c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
